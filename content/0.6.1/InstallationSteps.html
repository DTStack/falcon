<!DOCTYPE html>
<!--
 | Generated by Apache Maven Doxia at 2016-03-11
 | Rendered using Apache Maven Fluido Skin 1.3.0
-->
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="Date-Revision-yyyymmdd" content="20160311" />
    <meta http-equiv="Content-Language" content="en" />
    <title>Falcon - Building & Installing Falcon</title>
    <link rel="stylesheet" href="./css/apache-maven-fluido-1.3.0.min.css" />
    <link rel="stylesheet" href="./css/site.css" />
    <link rel="stylesheet" href="./css/print.css" media="print" />

      
    <script type="text/javascript" src="./js/apache-maven-fluido-1.3.0.min.js"></script>

                          
        
<script type="text/javascript">$( document ).ready( function() { $( '.carousel' ).carousel( { interval: 3500 } ) } );</script>
          
            </head>
        <body class="topBarDisabled">
          
                        
                    
    
        <div class="container">
          <div id="banner">
        <div class="pull-left">
                                <div id="bannerLeft">
                                                                                                <img src="images/falcon-logo.png"  alt="Apache Falcon" width="200px" height="45px"/>
                </div>
                      </div>
        <div class="pull-right">  </div>
        <div class="clear"><hr/></div>
      </div>

      <div id="breadcrumbs">
        <ul class="breadcrumb">
                
                    
                              <li class="">
                    <a href="index.html" title="Falcon">
        Falcon</a>
        </li>
      <li class="divider ">/</li>
        <li class="">Building & Installing Falcon</li>
        
                
                    
                  <li id="publishDate" class="pull-right">Last Published: 2016-03-11</li> <li class="divider pull-right">|</li>
              <li id="projectVersion" class="pull-right">Version: 0.6.1</li>
            
                            </ul>
      </div>

      
                
        <div id="bodyColumn" >
                                  
            <div class="section">
<h3>Building &amp; Installing Falcon<a name="Building__Installing_Falcon"></a></h3></div>
<div class="section">
<h4>Building Falcon<a name="Building_Falcon"></a></h4>
<div class="source">
<pre>
You would need the following installed to build Falcon

* JDK 1.7
* Maven 3.x

git clone https://git-wip-us.apache.org/repos/asf/falcon.git falcon

cd falcon

export MAVEN_OPTS=&quot;-Xmx1024m -XX:MaxPermSize=256m -noverify&quot; &amp;&amp; mvn clean install

[optionally -Dhadoop.version=&lt;&lt;hadoop.version&gt;&gt; can be appended to build for a specific version of hadoop]
*Note:* Falcon drops support for Hadoop-1 and only supports Hadoop-2 from Falcon 0.6 onwards
[optionally -Doozie.version=&lt;&lt;oozie version&gt;&gt; can be appended to build with a specific version of oozie.
Oozie versions &gt;= 4 are supported]
Falcon build with JDK 1.7 using -noverify option


</pre></div>
<p>Once the build successfully completes, artifacts can be packaged for deployment. The package can be built in embedded or distributed mode.</p>
<p><b>Embedded Mode</b></p>
<div class="source">
<pre>

mvn clean assembly:assembly -DskipTests -DskipCheck=true


</pre></div>
<p>Tar can be found in {project dir}/target/apache-falcon-${project.version}-bin.tar.gz</p>
<p>Tar is structured as follows</p>
<div class="source">
<pre>

|- bin
   |- falcon
   |- falcon-start
   |- falcon-stop
   |- falcon-config.sh
   |- service-start.sh
   |- service-stop.sh
|- conf
   |- startup.properties
   |- runtime.properties
   |- client.properties
   |- log4j.xml
   |- falcon-env.sh
|- docs
|- client
   |- lib (client support libs)
|- server
   |- webapp
      |- falcon.war
|- hadooplibs
|- README
|- NOTICE.txt
|- LICENSE.txt
|- DISCLAIMER.txt
|- CHANGES.txt

</pre></div>
<p><b>Distributed Mode</b></p>
<div class="source">
<pre>

mvn clean assembly:assembly -DskipTests -DskipCheck=true -Pdistributed,hadoop-2


</pre></div>
<p>Tar can be found in {project dir}/target/apache-falcon-distributed-${project.version}-server.tar.gz</p>
<p>Tar is structured as follows</p>
<div class="source">
<pre>

|- bin
   |- falcon
   |- falcon-start
   |- falcon-stop
   |- falcon-config.sh
   |- service-start.sh
   |- service-stop.sh
   |- prism-stop
   |- prism-start
|- conf
   |- startup.properties
   |- runtime.properties
   |- client.properties
   |- log4j.xml
   |- falcon-env.sh
|- docs
|- client
   |- lib (client support libs)
|- server
   |- webapp
      |- falcon.war
      |- prism.war
|- hadooplibs
|- README
|- NOTICE.txt
|- LICENSE.txt
|- DISCLAIMER.txt
|- CHANGES.txt

</pre></div></div>
<div class="section">
<h4>Installing &amp; running Falcon<a name="Installing__running_Falcon"></a></h4>
<p><b>Installing falcon</b></p>
<div class="source">
<pre>
tar -xzvf {falcon package}
cd falcon-distributed-${project.version} or falcon-${project.version}

</pre></div>
<p><b>Configuring Falcon</b></p>
<p>By default config directory used by falcon is {package dir}/conf. To override this set environment variable FALCON_CONF to the path of the conf dir.</p>
<p>falcon-env.sh has been added to the falcon conf. This file can be used to set various environment variables that you need for you services. In addition you can set any other environment variables you might need. This file will be sourced by falcon scripts before any commands are executed. The following environment variables are available to set.</p>
<div class="source">
<pre>
# The java implementation to use. If JAVA_HOME is not found we expect java and jar to be in path
#export JAVA_HOME=

# any additional java opts you want to set. This will apply to both client and server operations
#export FALCON_OPTS=

# any additional java opts that you want to set for client only
#export FALCON_CLIENT_OPTS=

# java heap size we want to set for the client. Default is 1024MB
#export FALCON_CLIENT_HEAP=

# any additional opts you want to set for prism service.
#export FALCON_PRISM_OPTS=

# java heap size we want to set for the prism service. Default is 1024MB
#export FALCON_PRISM_HEAP=

# any additional opts you want to set for falcon service.
#export FALCON_SERVER_OPTS=

# java heap size we want to set for the falcon server. Default is 1024MB
#export FALCON_SERVER_HEAP=

# What is is considered as falcon home dir. Default is the base location of the installed software
#export FALCON_HOME_DIR=

# Where log files are stored. Default is logs directory under the base install location
#export FALCON_LOG_DIR=

# Where pid files are stored. Default is logs directory under the base install location
#export FALCON_PID_DIR=

# where the falcon active mq data is stored. Default is logs/data directory under the base install location
#export FALCON_DATA_DIR=

# Where do you want to expand the war file. By Default it is in /server/webapp dir under the base install dir.
#export FALCON_EXPANDED_WEBAPP_DIR=

</pre></div>
<p><b>Configuring Monitoring plugin to register catalog partitions</b> Falcon comes with a monitoring plugin that registers catalog partition. This comes in really handy during migration from filesystem based feeds to hcatalog based feeds. This plugin enables the user to de-couple the partition registration and assume that all partitions are already on hcatalog even before the migration, simplifying the hcatalog migration.</p>
<p>By default this plugin is disabled. To enable this plugin and leverage the feature, there are 3 pre-requisites:</p>
<div class="source">
<pre>
In {package dir}/conf/startup.properties, add
*.workflow.execution.listeners=org.apache.falcon.catalog.CatalogPartitionHandler

In the cluster definition, ensure registry endpoint is defined.
Ex:
&lt;interface type=&quot;registry&quot; endpoint=&quot;thrift://localhost:1109&quot; version=&quot;0.13.3&quot;/&gt;

In the feed definition, ensure the corresponding catalog table is mentioned in feed-properties
Ex:
&lt;properties&gt;
    &lt;property name=&quot;catalog.table&quot; value=&quot;catalog:default:in_table#year={YEAR};month={MONTH};day={DAY};hour={HOUR};minute={MINUTE}&quot;/&gt;
&lt;/properties&gt;

</pre></div>
<p><b>NOTE for Mac OS users</b></p>
<div class="source">
<pre>
If you are using a Mac OS, you will need to configure the FALCON_SERVER_OPTS (explained above).

In  {package dir}/conf/falcon-env.sh uncomment the following line
#export FALCON_SERVER_OPTS=

and change it to look as below
export FALCON_SERVER_OPTS=&quot;-Djava.awt.headless=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc=&quot;

</pre></div>
<p><b>Starting Falcon Server</b></p>
<div class="source">
<pre>
bin/falcon-start [-port &lt;port&gt;]

</pre></div>
<p>By default, * If falcon.enableTLS is set to true explicitly or not set at all, falcon starts at port 15443 on <a class="externalLink" href="https://">https://</a> by default. * If falcon.enableTLS is set to false explicitly, falcon starts at port 15000 on <a class="externalLink" href="http://.">http://.</a> * To change the port, use -port option.</p>
<ul>
<li>If falcon.enableTLS is not set explicitly, port that ends with 443 will automatically put falcon on <a class="externalLink" href="https://.">https://.</a> Any other port will put falcon on <a class="externalLink" href="http://.">http://.</a></li></ul>* falcon server starts embedded active mq. To control this behaviour, set the following system properties using -D option in environment variable FALCON_OPTS:
<ul>
<li>falcon.embeddedmq=&lt;true/false&gt; - Should server start embedded active mq, default true</li>
<li>falcon.embeddedmq.port=&lt;port&gt; - Port for embedded active mq, default 61616</li>
<li>falcon.embeddedmq.data=&lt;path&gt; - Data path for embedded active mq, default {package dir}/logs/data</li></ul>* falcon server starts with conf from {package dir}/conf. To override this (to use the same conf with multiple falcon upgrades), set environment variable FALCON_CONF to the path of conf dir
<p><b><i>Adding Extension Libraries</i></b> Library extensions allows users to add custom libraries to entity lifecycles such as feed retention, feed replication and process execution. This is useful for usecases such as adding filesystem extensions. To enable this, add the following configs to startup.properties: *.libext.paths=&lt;paths to be added to all entity lifecycles&gt; *.libext.feed.paths=&lt;paths to be added to all feed lifecycles&gt; *.libext.feed.retentions.paths=&lt;paths to be added to feed retention workflow&gt; *.libext.feed.replication.paths=&lt;paths to be added to feed replication workflow&gt; *.libext.process.paths=&lt;paths to be added to process workflow&gt;</p>
<p>The configured jars are added to falcon classpath and the corresponding workflows</p>
<p><b>Starting Prism</b></p>
<div class="source">
<pre>
bin/prism-start [-port &lt;port&gt;]

</pre></div>
<p>By default,  * prism server starts at port 16443. To change the port, use -port option</p>
<ul>
<li>falcon.enableTLS can be set to true or false explicitly to enable SSL, if not port that end with 443 will automatically put prism on <a class="externalLink" href="https://">https://</a></li></ul>* prism starts with conf from {package dir}/conf. To override this (to use the same conf with multiple prism upgrades), set environment variable FALCON_CONF to the path of conf dir
<p><b>Using Falcon</b></p>
<div class="source">
<pre>
bin/falcon admin -version
Falcon server build version: {Version:&quot;0.3-SNAPSHOT-rd7e2be9afa2a5dc96acd1ec9e325f39c6b2f17f7&quot;,Mode:&quot;embedded&quot;}

----

bin/falcon help
(for more details about falcon cli usage)

</pre></div>
<p><b>Dashboard</b></p>
<p>Once falcon / prism is started, you can view the status of falcon entities using the Web-based dashboard. The web UI works in both distributed and embedded mode. You can open your browser at the corresponding port to use the web UI.</p>
<p>Falcon dashboard makes the REST api calls as user &quot;falcon-dashboard&quot;. If this user does not exist on your falcon and oozie servers, please create the user.</p>
<div class="source">
<pre>
## create user.
[root@falconhost ~] useradd -U -m falcon-dashboard -G users

## verify user is created with membership in correct groups.
[root@falconhost ~] groups falcon-dashboard
falcon-dashboard : falcon-dashboard users
[root@falconhost ~]

</pre></div>
<p><b>Stopping Falcon Server</b></p>
<div class="source">
<pre>
bin/falcon-stop

</pre></div>
<p><b>Stopping Prism</b></p>
<div class="source">
<pre>
bin/prism-stop

</pre></div></div>
<div class="section">
<h4>Preparing Oozie and Falcon packages for deployment<a name="Preparing_Oozie_and_Falcon_packages_for_deployment"></a></h4>
<div class="source">
<pre>
cd &lt;&lt;project home&gt;&gt;
src/bin/package.sh &lt;&lt;hadoop-version&gt;&gt; &lt;&lt;oozie-version&gt;&gt;

&gt;&gt; ex. src/bin/package.sh 1.1.2 4.0.1 or src/bin/package.sh 0.20.2-cdh3u5 4.0.1
&gt;&gt; ex. src/bin/package.sh 2.5.0 4.0.0
&gt;&gt; Falcon package is available in &lt;&lt;falcon home&gt;&gt;/target/apache-falcon-&lt;&lt;version&gt;&gt;-bin.tar.gz
&gt;&gt; Oozie package is available in &lt;&lt;falcon home&gt;&gt;/target/oozie-4.0.1-distro.tar.gz

</pre></div></div>
<div class="section">
<h4>Running Examples using embedded package<a name="Running_Examples_using_embedded_package"></a></h4>
<div class="source">
<pre>
bin/falcon-start

</pre></div>
<p>Make sure the hadoop and oozie endpoints are according to your setup in examples/entity/filesystem/standalone-cluster.xml The cluster locations,staging and working dirs, MUST be created prior to submitting a cluster entity to Falcon. <b>staging</b> must have 777 permissions and the parent dirs must have execute permissions <b>working</b> must have 755 permissions and the parent dirs must have execute permissions</p>
<div class="source">
<pre>
bin/falcon entity -submit -type cluster -file examples/entity/filesystem/standalone-cluster.xml

</pre></div>
<p>Submit input and output feeds:</p>
<div class="source">
<pre>
bin/falcon entity -submit -type feed -file examples/entity/filesystem/in-feed.xml
bin/falcon entity -submit -type feed -file examples/entity/filesystem/out-feed.xml

</pre></div>
<p>Set-up workflow for the process:</p>
<div class="source">
<pre>
hadoop fs -put examples/app /

</pre></div>
<p>Submit and schedule the process:</p>
<div class="source">
<pre>
bin/falcon entity -submitAndSchedule -type process -file examples/entity/filesystem/oozie-mr-process.xml
bin/falcon entity -submitAndSchedule -type process -file examples/entity/filesystem/pig-process.xml

</pre></div>
<p>Generate input data:</p>
<div class="source">
<pre>
examples/data/generate.sh &lt;&lt;hdfs endpoint&gt;&gt;

</pre></div>
<p>Get status of instances:</p>
<div class="source">
<pre>
bin/falcon instance -status -type process -name oozie-mr-process -start 2013-11-15T00:05Z -end 2013-11-15T01:00Z

</pre></div>
<p>HCat based example entities are in examples/entity/hcat.</p></div>
                  </div>
          </div>

    <hr/>

    <footer>
            <div class="container">
              <div class="row span12">Copyright &copy;                    2013-2016
                        <a href="http://www.apache.org">Apache Software Foundation</a>.
            All Rights Reserved.      
                    
      </div>

                          
                <p id="poweredBy" class="pull-right">
                          <a href="http://maven.apache.org/" title="Built by Maven" class="poweredBy">
        <img class="builtBy" alt="Built by Maven" src="./images/logos/maven-feather.png" />
      </a>
              </p>
        
                </div>
    </footer>
  </body>
</html>
